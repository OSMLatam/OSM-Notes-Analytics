#!/usr/bin/env bats

# Load test helper for database connection verification
load ../../test_helper

# Tests for hybrid strategy: copy base tables for initial load, FDW for incremental
#
# Author: Andres Gomez (AngocA)
# Version: 2025-10-27

# Test configuration
TEST_INGESTION_DB="osm_notes_dwh_test1"
TEST_ANALYTICS_DB="osm_notes_dwh_test2"

# Helper: Wait for database to be ready
wait_for_db() {
	local dbname="$1"
	local max_attempts=10
	local attempt=0
	while [[ ${attempt} -lt ${max_attempts} ]]; do
		if psql -d "${dbname}" -c "SELECT 1;" >/dev/null 2>&1; then
			return 0
		fi
		sleep 0.2
		attempt=$((attempt + 1))
	done
	return 1
}

setup() {
	# Setup test databases (order matters: ingestion first, then analytics)
	create_test_ingestion_db
	wait_for_db "${TEST_INGESTION_DB}" || skip "Cannot connect to test ingestion DB"
	populate_test_ingestion_data
	create_test_analytics_db
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Cannot connect to test analytics DB"
}

teardown() {
	# Cleanup test databases
	psql -d postgres -c "DROP DATABASE IF EXISTS ${TEST_INGESTION_DB};" 2>/dev/null || true
	psql -d postgres -c "DROP DATABASE IF EXISTS ${TEST_ANALYTICS_DB};" 2>/dev/null || true
}

# Helper: Create test ingestion database
create_test_ingestion_db() {
	psql -d postgres -c "DROP DATABASE IF EXISTS ${TEST_INGESTION_DB};" 2>/dev/null || true
	psql -d postgres -c "CREATE DATABASE ${TEST_INGESTION_DB};" || skip "Cannot create test ingestion DB"

	# Wait for database to be ready
	sleep 0.3

	# Create base tables in ingestion DB
	psql -d "${TEST_INGESTION_DB}" <<'EOF' || skip "Cannot create tables in ingestion DB"
  CREATE TABLE public.notes (
   note_id BIGINT PRIMARY KEY,
   latitude DECIMAL(10, 8),
   longitude DECIMAL(11, 8),
   created_at TIMESTAMP WITH TIME ZONE,
   id_country INTEGER,
   id_user BIGINT
  );

  CREATE TABLE public.note_comments (
   note_id BIGINT,
   sequence_action INTEGER,
   event TEXT,
   id_user BIGINT,
   created_at TIMESTAMP WITH TIME ZONE,
   PRIMARY KEY (note_id, sequence_action)
  );

  CREATE TABLE public.note_comments_text (
   note_id BIGINT,
   sequence_action INTEGER,
   body TEXT,
   PRIMARY KEY (note_id, sequence_action)
  );

  CREATE TABLE public.users (
   user_id BIGINT PRIMARY KEY,
   username TEXT
  );

  CREATE TABLE public.countries (
   country_id INTEGER PRIMARY KEY,
   country_name TEXT,
   country_name_es TEXT,
   country_name_en TEXT
  );
EOF
}

# Helper: Create test analytics database
create_test_analytics_db() {
	psql -d postgres -c "DROP DATABASE IF EXISTS ${TEST_ANALYTICS_DB};" 2>/dev/null || true
	psql -d postgres -c "CREATE DATABASE ${TEST_ANALYTICS_DB};" || skip "Cannot create test analytics DB"

	# Wait for database to be ready
	sleep 0.3

	# Create dwh schema
	psql -d "${TEST_ANALYTICS_DB}" -c "CREATE SCHEMA IF NOT EXISTS dwh;" || true
}

# Helper: Populate test data in ingestion DB
populate_test_ingestion_data() {
	psql -d "${TEST_INGESTION_DB}" <<'EOF'
  -- Insert test countries
  INSERT INTO public.countries (country_id, country_name, country_name_en) VALUES
   (1, 'Colombia', 'Colombia'),
   (2, 'Estados Unidos', 'United States');

  -- Insert test users
  INSERT INTO public.users (user_id, username) VALUES
   (100, 'testuser1'),
   (200, 'testuser2');

  -- Insert test notes
  INSERT INTO public.notes (note_id, latitude, longitude, created_at, id_country, id_user) VALUES
   (1, 4.6097, -74.0817, '2024-01-01 10:00:00+00', 1, 100),
   (2, 40.7128, -74.0060, '2024-01-02 11:00:00+00', 2, 200);

  -- Insert test note_comments
  INSERT INTO public.note_comments (note_id, sequence_action, event, id_user, created_at) VALUES
   (1, 1, 'opened', 100, '2024-01-01 10:00:00+00'),
   (1, 2, 'commented', 200, '2024-01-01 11:00:00+00'),
   (1, 3, 'closed', 100, '2024-01-01 12:00:00+00'),
   (2, 1, 'opened', 200, '2024-01-02 11:00:00+00');

  -- Insert test note_comments_text
  INSERT INTO public.note_comments_text (note_id, sequence_action, body) VALUES
   (1, 1, 'Opening note'),
   (1, 2, 'Comment on note'),
   (1, 3, 'Closing note'),
   (2, 1, 'Opening note 2');
EOF
}

# Test: copyBaseTables.sh copies all tables correctly
@test "copyBaseTables.sh copies all base tables" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Set environment variables for script
	export DBNAME_INGESTION="${TEST_INGESTION_DB}"
	export DBNAME_DWH="${TEST_ANALYTICS_DB}"
	# Don't set DB_USER_* to use peer authentication in tests
	# Unset before running script to override defaults from etc/properties.sh
	unset DB_USER_INGESTION DB_USER_DWH DB_USER

	# Run copy script
	run bash "${SCRIPT_BASE_DIRECTORY}/bin/dwh/copyBaseTables.sh"
	[ "${status}" -eq 0 ] || echo "Script exit status: ${status}"

	# Verify all tables were copied
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('notes', 'note_comments', 'note_comments_text', 'users', 'countries');"
	table_count="${output// /}"
	[ "${table_count}" = "5" ] || echo "Expected 5 tables, found: ${table_count}"

	# Verify row counts match
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM public.notes;"
	local analytics_count="${output// /}"
	run psql -d "${TEST_INGESTION_DB}" -t -c "SELECT COUNT(*) FROM public.notes;"
	local ingestion_count="${output// /}"
	[ "${analytics_count}" = "${ingestion_count}" ]
}

# Test: copyBaseTables.sh handles missing tables gracefully
@test "copyBaseTables.sh handles missing source tables" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Clean up any existing tables in analytics DB from previous tests
	psql -d "${TEST_ANALYTICS_DB}" -c "DROP TABLE IF EXISTS public.notes, public.note_comments, public.note_comments_text, public.users, public.countries CASCADE;" 2>/dev/null || true

	# Set environment variables
	export DBNAME_INGESTION="${TEST_INGESTION_DB}"
	export DBNAME_DWH="${TEST_ANALYTICS_DB}"
	# Don't set DB_USER_* to use peer authentication in tests
	unset DB_USER_INGESTION DB_USER_DWH DB_USER

	# Drop one table from source
	psql -d "${TEST_INGESTION_DB}" -c "DROP TABLE IF EXISTS public.note_comments_text;" || true

	# Run copy script (should continue with other tables)
	run bash "${SCRIPT_BASE_DIRECTORY}/bin/dwh/copyBaseTables.sh"
	[ "${status}" -eq 0 ]

	# Verify other tables were still copied
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('notes', 'note_comments', 'users', 'countries');"
	table_count="${output// /}"
	[ "${table_count}" = "4" ]
}

# Test: dropCopiedBaseTables.sh drops all copied tables
@test "dropCopiedBaseTables.sh drops all copied tables" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Clean up any existing tables in analytics DB from previous tests
	psql -d "${TEST_ANALYTICS_DB}" -c "DROP TABLE IF EXISTS public.notes, public.note_comments, public.note_comments_text, public.users, public.countries CASCADE;" 2>/dev/null || true

	# First copy tables
	export DBNAME_INGESTION="${TEST_INGESTION_DB}"
	export DBNAME_DWH="${TEST_ANALYTICS_DB}"
	# Don't set DB_USER_* to use peer authentication in tests
	unset DB_USER_INGESTION DB_USER_DWH DB_USER

	bash "${SCRIPT_BASE_DIRECTORY}/bin/dwh/copyBaseTables.sh" || skip "Failed to copy tables"

	# Verify tables exist
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('notes', 'note_comments', 'note_comments_text', 'users', 'countries');"
	table_count="${output// /}"
	[ "${table_count}" = "5" ]

	# Run drop script
	run bash "${SCRIPT_BASE_DIRECTORY}/bin/dwh/dropCopiedBaseTables.sh"
	[ "${status}" -eq 0 ]

	# Verify all tables were dropped
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('notes', 'note_comments', 'note_comments_text', 'users', 'countries');"
	table_count="${output// /}"
	[ "${table_count}" = "0" ]
}

# Test: FDW setup creates foreign tables correctly
@test "ETL_60_setupFDW.sql creates foreign tables" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Setup requires ingestion DB to exist
	# Use current user for FDW (peer authentication)
	export FDW_INGESTION_HOST="localhost"
	export FDW_INGESTION_DBNAME="${TEST_INGESTION_DB}"
	export FDW_INGESTION_PORT="5432"
	export FDW_INGESTION_USER="${USER:-$(whoami)}"
	export FDW_INGESTION_PASSWORD=""
	export FDW_INGESTION_PASSWORD_VALUE=""
	export ETL_ANALYZE_FDW_TABLES_VALUE="false"

	# Run FDW setup (ignore connection errors during ANALYZE, just verify tables are created)
	envsubst <"${SCRIPT_BASE_DIRECTORY}/sql/dwh/ETL_60_setupFDW.sql" |
		psql -d "${TEST_ANALYTICS_DB}" -v ON_ERROR_STOP=0 2>&1 | grep -v "ERROR.*could not connect" || true

	# Verify foreign tables were created (even if connection fails)
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.foreign_tables WHERE foreign_table_schema = 'public' AND foreign_table_name IN ('notes', 'note_comments', 'note_comments_text', 'users', 'countries');"
	table_count="${output// /}"
	[ "${table_count}" = "5" ]

	# Verify foreign server exists
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM pg_foreign_server WHERE srvname = 'ingestion_server';"
	server_count="${output// /}"
	[ "${server_count}" = "1" ]
}

# Test: Foreign tables can query data from ingestion DB
@test "Foreign tables can query data from ingestion DB" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Setup FDW
	# Use current user for FDW (peer authentication)
	export FDW_INGESTION_HOST="localhost"
	export FDW_INGESTION_DBNAME="${TEST_INGESTION_DB}"
	export FDW_INGESTION_PORT="5432"
	export FDW_INGESTION_USER="${USER:-$(whoami)}"
	export FDW_INGESTION_PASSWORD=""
	export FDW_INGESTION_PASSWORD_VALUE=""
	export ETL_ANALYZE_FDW_TABLES_VALUE="false"

	envsubst <"${SCRIPT_BASE_DIRECTORY}/sql/dwh/ETL_60_setupFDW.sql" |
		psql -d "${TEST_ANALYTICS_DB}" -v ON_ERROR_STOP=0 2>&1 | grep -v "ERROR.*could not connect" || true

	# Verify foreign table exists (connection may fail, but table structure should be created)
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.foreign_tables WHERE foreign_table_schema = 'public' AND foreign_table_name = 'notes';"
	table_count="${output// /}"
	[ "${table_count}" = "1" ]

	# Verify foreign table structure exists
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.columns WHERE table_schema = 'public' AND table_name = 'notes' AND column_name = 'note_id';"
	column_count="${output// /}"
	[ "${column_count}" = "1" ]
}

# Test: Initial load uses copied tables (not FDW)
@test "Initial load uses copied local tables" {
	# Ensure databases are ready and have required tables
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Verify ingestion DB has required tables, recreate if needed
	if ! psql -d "${TEST_INGESTION_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('notes', 'note_comments', 'note_comments_text', 'users', 'countries');" | grep -q "5"; then
		# Recreate ingestion DB if tables are missing
		create_test_ingestion_db || skip "Cannot recreate ingestion DB"
		populate_test_ingestion_data || skip "Cannot populate ingestion DB"
	fi

	# Clean up any existing tables in analytics DB from previous tests
	psql -d "${TEST_ANALYTICS_DB}" -c "DROP TABLE IF EXISTS public.notes, public.note_comments, public.note_comments_text, public.users, public.countries CASCADE;" 2>/dev/null || true

	# Copy tables first
	export DBNAME_INGESTION="${TEST_INGESTION_DB}"
	export DBNAME_DWH="${TEST_ANALYTICS_DB}"
	# Don't set DB_USER_* to use peer authentication in tests
	unset DB_USER_INGESTION DB_USER_DWH DB_USER

	bash "${SCRIPT_BASE_DIRECTORY}/bin/dwh/copyBaseTables.sh" || skip "Failed to copy tables"

	# Verify tables are local (not foreign)
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'notes' AND table_type = 'BASE TABLE';"
	table_count="${output// /}"
	[ "${table_count}" = "1" ]

	# Verify no foreign tables exist yet
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.foreign_tables WHERE foreign_table_schema = 'public';"
	foreign_count="${output// /}"
	[ "${foreign_count}" = "0" ]
}

# Test: Incremental load uses FDW (not local tables)
@test "Incremental load uses foreign tables" {
	# Ensure databases are ready
	wait_for_db "${TEST_INGESTION_DB}" || skip "Ingestion DB not ready"
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Setup FDW for incremental
	# Use current user for FDW (peer authentication)
	export FDW_INGESTION_HOST="localhost"
	export FDW_INGESTION_DBNAME="${TEST_INGESTION_DB}"
	export FDW_INGESTION_PORT="5432"
	export FDW_INGESTION_USER="${USER:-$(whoami)}"
	export FDW_INGESTION_PASSWORD=""
	export FDW_INGESTION_PASSWORD_VALUE=""
	export ETL_ANALYZE_FDW_TABLES_VALUE="false"

	envsubst <"${SCRIPT_BASE_DIRECTORY}/sql/dwh/ETL_60_setupFDW.sql" |
		psql -d "${TEST_ANALYTICS_DB}" -v ON_ERROR_STOP=0 2>&1 | grep -v "ERROR.*could not connect" || true

	# Verify foreign tables exist (even if connection fails)
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.foreign_tables WHERE foreign_table_schema = 'public' AND foreign_table_name = 'note_comments';"
	table_count="${output// /}"
	[ "${table_count}" = "1" ]

	# Verify foreign table structure exists
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.columns WHERE table_schema = 'public' AND table_name = 'note_comments' AND column_name = 'note_id';"
	column_count="${output// /}"
	[ "${column_count}" = "1" ]
}

# Test: FDW setup is skipped when databases are the same
@test "FDW setup is skipped when DBNAME_INGESTION equals DBNAME_DWH" {
	# Ensure databases are ready
	wait_for_db "${TEST_ANALYTICS_DB}" || skip "Analytics DB not ready"

	# Create DWH schema if it doesn't exist
	psql -d "${TEST_ANALYTICS_DB}" -c "CREATE SCHEMA IF NOT EXISTS dwh;" || true

	# Set both databases to the same value
	export DBNAME_INGESTION="${TEST_ANALYTICS_DB}"
	export DBNAME_DWH="${TEST_ANALYTICS_DB}"
	# Don't set DB_USER_* to use peer authentication in tests
	unset DB_USER_INGESTION DB_USER_DWH DB_USER

	# Create a minimal DWH structure to simulate incremental execution
	psql -d "${TEST_ANALYTICS_DB}" <<'EOF' || true
  -- Create a minimal facts table to simulate existing DWH
  CREATE TABLE IF NOT EXISTS dwh.facts (
   fact_id BIGSERIAL PRIMARY KEY,
   note_id BIGINT,
   created_at TIMESTAMP WITH TIME ZONE
  );
  INSERT INTO dwh.facts (note_id, created_at) VALUES (1, NOW());
EOF

	# Run ETL processNotesETL function logic (simulating incremental execution)
	# This should skip FDW setup since databases are the same
	export DBNAME="${TEST_ANALYTICS_DB}"

	# Capture ETL output to verify FDW skip message
	run bash -c "
  source ${SCRIPT_BASE_DIRECTORY}/lib/osm-common/commonFunctions.sh 2>/dev/null || true
  source ${SCRIPT_BASE_DIRECTORY}/lib/osm-common/bash_logger.sh 2>/dev/null || true
  cd ${SCRIPT_BASE_DIRECTORY}
  export DBNAME_INGESTION=\"${TEST_ANALYTICS_DB}\"
  export DBNAME_DWH=\"${TEST_ANALYTICS_DB}\"
  unset DB_USER_INGESTION DB_USER_DWH DB_USER
  # Simulate the FDW check logic from ETL.sh
  ingestion_db=\"\${DBNAME_INGESTION:-\${DBNAME:-osm_notes}}\"
  analytics_db=\"\${DBNAME_DWH:-\${DBNAME:-osm_notes}}\"
  if [[ \"\${ingestion_db}\" != \"\${analytics_db}\" ]]; then
   echo 'FDW would be configured'
   exit 1
  else
   echo 'FDW setup skipped - databases are the same'
  fi
 "

	[ "${status}" -eq 0 ]
	[[ "${output}" == *"FDW setup skipped - databases are the same"* ]]

	# Verify no foreign tables were created (since FDW was skipped)
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM information_schema.foreign_tables WHERE foreign_table_schema = 'public';"
	foreign_count="${output// /}"
	[ "${foreign_count}" = "0" ]

	# Verify no foreign server was created
	run psql -d "${TEST_ANALYTICS_DB}" -t -c "SELECT COUNT(*) FROM pg_foreign_server WHERE srvname = 'ingestion_server';"
	server_count="${output// /}"
	[ "${server_count}" = "0" ]
}
